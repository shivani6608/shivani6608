
installing libraries
import sklearn
import numpy
import os
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import pylab as pl
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
%matplotlib inline
by using dataset of iris.csv
df=pd.read_csv("iris.csv")
df.head()
sepal-length	sepal-width	petal-length	petal-width	species
0	5.1	3.5	1.4	0.2	Iris-setosa
1	4.9	3.0	1.4	0.2	Iris-setosa
2	4.7	3.2	1.3	0.2	Iris-setosa
3	4.6	3.1	1.5	0.2	Iris-setosa
4	5.0	3.6	1.4	0.2	Iris-setosa
df.describe()
sepal-length	sepal-width	petal-length	petal-width
count	150.000000	150.000000	150.000000	150.000000
mean	5.843333	3.054000	3.758667	1.198667
std	0.828066	0.433594	1.764420	0.763161
min	4.300000	2.000000	1.000000	0.100000
25%	5.100000	2.800000	1.600000	0.300000
50%	5.800000	3.000000	4.350000	1.300000
75%	6.400000	3.300000	5.100000	1.800000
max	7.900000	4.400000	6.900000	2.500000
cdf=df[['sepal-length','sepal-width','petal-length','petal-width']]
cdf.head(10)
sepal-length	sepal-width	petal-length	petal-width
0	5.1	3.5	1.4	0.2
1	4.9	3.0	1.4	0.2
2	4.7	3.2	1.3	0.2
3	4.6	3.1	1.5	0.2
4	5.0	3.6	1.4	0.2
5	5.4	3.9	1.7	0.4
6	4.6	3.4	1.4	0.3
7	5.0	3.4	1.5	0.2
8	4.4	2.9	1.4	0.2
9	4.9	3.1	1.5	0.1
Analysis
df.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 150 entries, 0 to 149
Data columns (total 5 columns):
 #   Column        Non-Null Count  Dtype  
---  ------        --------------  -----  
 0   sepal-length  150 non-null    float64
 1   sepal-width   150 non-null    float64
 2   petal-length  150 non-null    float64
 3   petal-width   150 non-null    float64
 4   species       150 non-null    object 
dtypes: float64(4), object(1)
memory usage: 6.0+ KB
df['species'].value_counts()
species
Iris-setosa        50
Iris-versicolor    50
Iris-virginica     50
Name: count, dtype: int64
df.isnull().sum()
sepal-length    0
sepal-width     0
petal-length    0
petal-width     0
species         0
dtype: int64
Visualization of data
df['sepal-length'].hist()
<Axes: >

df['sepal-width'].hist()
<Axes: >

 
df['petal-length'].hist()
<Axes: >

df['petal-width'].hist()
<Axes: >

sns.pairplot(df,hue='species')
<seaborn.axisgrid.PairGrid at 0x1fe77549390>

colors = ['red', 'purple', 'green']
species = ['Iris-virginica','Iris-versicolor','Iris-setosa']
for i in range(3):
    x = df[df['species'] == species[i]]
    plt.scatter(x['sepal-length'], x['sepal-width'], c = colors[i], label=species[i])
plt.xlabel("Sepal Length")
plt.ylabel("Sepal Width")
plt.legend()
<matplotlib.legend.Legend at 0x1fe79881f10>

for i in range(3):
    x = df[df['species'] == species[i]]
    plt.scatter(x['petal-length'], x['petal-width'], c = colors[i], label=species[i])
plt.xlabel("petal Length")
plt.ylabel("petal Width")
plt.legend()
<matplotlib.legend.Legend at 0x1fe79a7e410>

for i in range(3):
    x = df[df['species'] == species[i]]
    plt.scatter(x['sepal-length'], x['petal-length'], c = colors[i], label=species[i])
plt.xlabel("Sepal Length")
plt.ylabel("petal length")
plt.legend()
<matplotlib.legend.Legend at 0x1fe79adbe10>

for i in range(3):
    x = df[df['species'] == species[i]]
    plt.scatter(x['sepal-width'], x['petal-width'], c = colors[i], label=species[i])
plt.xlabel("Sepal width")
plt.ylabel("petal Width")
plt.legend()
<matplotlib.legend.Legend at 0x1fe79ac8910>

Scatter Matrix
from sklearn.preprocessing import LabelEncoder
df.species=LabelEncoder().fit_transform(df.species)
from pandas.plotting import scatter_matrix
scatter_matrix(df,figsize=(12,12))
plt.show()

Correlation
sns.heatmap(df.corr(),annot=True)
<Axes: >

 
Modeling Training And testing:
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier

X=df.drop(columns=['species'])
Y=df['species']
X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.30)
#logistric Regression
model=LogisticRegression()
model.fit(X_train,Y_train)
print("Logistic Regreesion Accuracy:",model.score(X_test,Y_test)*100)
Logistic Regreesion Accuracy: 100.0
model training
model.fit(X_train.values,Y_train.values)
LogisticRegression()
In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.
On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.
#print metric to get performance
print("Accuracy:",model.score(X_test,Y_test)*100)
Accuracy: 100.0
#K-nearest neighbors
model=KNeighborsClassifier()
model.fit(X_train.values,Y_train.values)
print("K-nearest neighbors Accuracy:",model.score(X_test,Y_test)*100)
K-nearest neighbors Accuracy: 100.0
model.fit(X_train.values,Y_train.values)
KNeighborsClassifier()
In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.
On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.
#print metric to get performanace
print("Accuracy:",model.score(X_test,Y_test)*100)
Accuracy: 100.0
#Decision tree
model=DecisionTreeClassifier()
model.fit(X_train.values,Y_train.values)
print("Decision Tree Accuracy:",model.score(X_test,Y_test)*100)
Decision Tree Accuracy: 100.0
model.fit(X_train.values,Y_train.values)
DecisionTreeClassifier()
In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.
On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.
#print metric to get performanace
print("Accuracy:",model.score(X_test,Y_test)*100)
Accuracy: 100.0
Predicting the model
import pickle
filename='saved_model.sav'
try:
    with open(filename,'wb') as file:
        pickle.dump(model,file)
    print("Model saved successfully.")
except Exception as e:
    print(f"Error saving the model: {e}")
Model saved successfully.
load_model=pickle.load(open(filename,'rb'))
load_model.predict([[6.0,2.2,4.0,1.0]])
array([1])
X_test.head()
sepal-length	sepal-width	petal-length	petal-width
15	5.7	4.4	1.5	0.4
94	5.6	2.7	4.2	1.3
56	6.3	3.3	4.7	1.6
0	5.1	3.5	1.4	0.2
54	6.5	2.8	4.6	1.5
load_model.predict([[4,2.5,3.0,4.0]])
array([1])
 
